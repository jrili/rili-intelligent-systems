{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS280 Programming Assignment 2\n",
    "__Implementing the Backpropagation Algorithm__<br>\n",
    "<br>\n",
    "Compiler: Python 3.6.5<br>\n",
    "OS: Windows 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.genfromtxt('training_set.csv', delimiter=',')\n",
    "train_labels = np.genfromtxt('training_labels.csv', delimiter=',')\n",
    "\n",
    "validation_data = np.genfromtxt('validation_set.csv', delimiter=',')\n",
    "validation_labels = np.genfromtxt('validation_labels.csv', delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_to_onehotvector(labels):\n",
    "    unique_labels, label_counts = np.unique(labels, return_counts=True)\n",
    "    onehotvector = np.zeros((len(labels), len(unique_labels)))\n",
    "    for index, label in enumerate(labels):\n",
    "        onehotvector[int(index), int(label)-1] = int(1)\n",
    "    return onehotvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehotvectors_to_labels(onehotvectors):\n",
    "    labels = np.zeros(onehotvectors.shape[0])\n",
    "    for index, onehotvector in enumerate(onehotvectors):\n",
    "        target_label = np.argwhere(onehotvector/np.max(onehotvector) == 1)\n",
    "        labels[index] = target_label + 1 # +1 because there is no class 0\n",
    "        #print('onehotvector[%d]='%(index), onehotvector)\n",
    "        #print('labels[%d]=%d'%(index,labels[index]))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = labels_to_onehotvector(train_labels)\n",
    "validation_labels = labels_to_onehotvector(validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7674, 354), (7674, 8), (1910, 354), (1910, 8))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, train_labels.shape, validation_data.shape, validation_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data = np.array([[0, 0, 0],\n",
    "#                       [0, 0, 1],\n",
    "#                       [0, 1, 0],\n",
    "#                       [0, 1, 1],\n",
    "#                       [1, 0, 0],\n",
    "#                       [1, 0, 1],\n",
    "#                       [1, 1, 0],\n",
    "#                       [1, 1, 1]])\n",
    "#train_labels = np.array([[0, 0, 0],\n",
    "#                       [1, 1, 0],\n",
    "#                       [1, 0, 1],\n",
    "#                       [0, 1, 1],\n",
    "#                       [0, 1, 1],\n",
    "#                       [1, 0, 0],\n",
    "#                       [1, 1, 0],\n",
    "#                       [0, 0, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Neural network\n",
    "Define architecture of Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_INPUT = train_data.shape[1]\n",
    "NUM_HIDDEN1_NEURONS = 7\n",
    "NUM_HIDDEN2_NEURONS = 5\n",
    "NUM_OUTPUT = train_labels.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Learning Rate, LR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare the matrices for the weights and biases, and then initialize them with random numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_neurons(num_input, num_hidden1_neurons, num_hidden2_neurons, num_output):\n",
    "    \n",
    "    INIT_RANGE = 0.1\n",
    "\n",
    "    x_in = np.zeros((num_input, 1))\n",
    "\n",
    "    w_h1 = np.random.uniform(low=-INIT_RANGE, high=INIT_RANGE, size=(num_hidden1_neurons, num_input))\n",
    "    b_h1 = np.random.uniform(low=-INIT_RANGE, high=INIT_RANGE, size=(num_hidden1_neurons, 1))\n",
    "\n",
    "    w_h2 = np.random.uniform(low=-INIT_RANGE, high=INIT_RANGE, size=(num_hidden2_neurons, num_hidden1_neurons))\n",
    "    b_h2 = np.random.uniform(low=-INIT_RANGE, high=INIT_RANGE, size=(num_hidden2_neurons, 1))\n",
    "\n",
    "    w_out = np.random.uniform(low=-INIT_RANGE, high=INIT_RANGE, size=(num_output, num_hidden2_neurons))\n",
    "    b_out = np.random.uniform(low=-INIT_RANGE, high=INIT_RANGE, size=(num_output, 1))\n",
    "\n",
    "    d_out = np.zeros((num_output, 1))\n",
    "    \n",
    "    return x_in, w_h1, b_h1, w_h2, b_h2, w_out, b_out, d_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Phase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_data, w_h1, b_h1, w_h2, b_h2, w_out, b_out):\n",
    "    ##### FORWARD PASS #####\n",
    "    ## HIDDEN LAYER 1\n",
    "    v_h1 = np.dot(w_h1,input_data) + b_h1\n",
    "    y_h1 = 1/(1 + np.exp(-v_h1))\n",
    "    ## HIDDEN LAYER 2\n",
    "    v_h2 = np.dot(w_h2, y_h1) + b_h2\n",
    "    y_h2 = 1/(1 + np.exp(-v_h2))            \n",
    "    ## OUTPUT LAYER\n",
    "    v_out = np.dot(w_out, y_h2) + b_out\n",
    "    out = 1/(1 + np.exp(-v_out))\n",
    "    \n",
    "    return out, y_h1, y_h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch(batch_data, w_h1, b_h1, w_h2, b_h2, w_out, b_out, labels=None):\n",
    "    total_error = 0\n",
    "    num_classes = b_out.shape[0]\n",
    "    onehotvector_predictions = np.zeros((batch_data.shape[0], num_classes))\n",
    "    for index, data in enumerate(batch_data):\n",
    "        error = 0\n",
    "        x_in = batch_data[index].reshape(-1, 1)\n",
    "            \n",
    "        out, dummy1, dummy2 = predict(x_in, w_h1, b_h1, w_h2, b_h2, w_out, b_out)\n",
    "        #print('onehotvector_predictions[%d].shape='%(index), onehotvector_predictions[index].shape)\n",
    "        #print('out.shape=', out.shape)\n",
    "        onehotvector_predictions[index] = out.reshape(-1,)\n",
    "        \n",
    "        if labels is not None:\n",
    "            d_out = labels[index].reshape(-1, 1)\n",
    "            error = d_out - out\n",
    "            total_error = total_error + np.sum(error*error)\n",
    "    total_error *= (1/batch_data.shape[0])\n",
    "    predictions = onehotvectors_to_labels(onehotvector_predictions)\n",
    "    \n",
    "    return total_error, predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fourlayer_neural_net(train_data, train_labels,num_input, num_hidden1_neurons,\n",
    "                               num_hidden2_neurons, num_output, validation_data=None, validation_labels=None):\n",
    "    \n",
    "    MAX_EPOCH = 30000\n",
    "    ERR_REPORT_PERIOD = 100 # Print error report every __ epochs\n",
    "    ERR_TERMINATION_COND = 0.0010000000000\n",
    "\n",
    "    x_in, w_h1, b_h1, w_h2, b_h2, w_out, b_out, d_out = init_neurons(num_input,\n",
    "                                                                     num_hidden1_neurons,\n",
    "                                                                     num_hidden2_neurons,\n",
    "                                                                     num_output)\n",
    "    # Initialize\n",
    "    total_error = np.zeros((MAX_EPOCH, 1))\n",
    "    total_validation_error = np.zeros((MAX_EPOCH, 1))\n",
    "    training_ending_epoch = MAX_EPOCH\n",
    "    epochs = range(0, MAX_EPOCH)\n",
    "    \n",
    "    for epoch_index in epochs:\n",
    "        train_indices = np.random.permutation(train_data.shape[0])\n",
    "        for train_index in train_indices:\n",
    "            # READ DATA\n",
    "            x_in = train_data[train_index].reshape(-1, 1)\n",
    "\n",
    "            ##### FORWARD PASS #####\n",
    "            out, y_h1, y_h2 = predict(x_in, w_h1, b_h1, w_h2, b_h2, w_out, b_out)\n",
    "            \n",
    "            ##### BACK PROPAGATION #####\n",
    "            d_out = train_labels[train_index].reshape(-1, 1)\n",
    "            error = d_out - out\n",
    "            #print('\\terror: ', error, '\\n')\n",
    "            delta_out = error*out*(1-out)\n",
    "            #print('delta-out.shape=',delta_out.shape)\n",
    "            #print('(1-y_h2).shape=',(1-y_h2).shape, ' y_h2*(1-y_h2).shape=', (y_h2*(1-y_h2)).shape, ' np.dot(w_out,delta_out).shape=', (np.dot(np.transpose(w_out),delta_out)).shape)\n",
    "            delta_h2 = (y_h2*(1-y_h2))*(np.dot(np.transpose(w_out),delta_out))\n",
    "            delta_h1 = (y_h1*(1-y_h1))*(np.dot(np.transpose(w_h2), delta_h2))\n",
    "\n",
    "            ## Update the weights and biases\n",
    "            w_out = w_out + LR*delta_out*np.transpose(y_h2)\n",
    "            b_out = b_out + LR*delta_out\n",
    "            \n",
    "            w_h2 = w_h2 + LR*delta_h2*np.transpose(y_h1)\n",
    "            b_h2 = b_h2 + LR*delta_h2\n",
    "            \n",
    "            w_h1 = w_h1 + LR*delta_h1*np.transpose(x_in)\n",
    "            b_h1 = b_h1 + LR*delta_h1\n",
    "            \n",
    "            total_error[epoch_index] = total_error[epoch_index] + np.sum(error*error)\n",
    "        \n",
    "        total_error[epoch_index] *= (1/train_data.shape[0])\n",
    "        \n",
    "        if validation_data is not None:\n",
    "            total_validation_error[epoch_index], predictions = predict_batch(validation_data,\n",
    "                                                                             w_h1, b_h1, w_h2,\n",
    "                                                                             b_h2, w_out, b_out, validation_labels)\n",
    "            \n",
    "        if epoch_index % ERR_REPORT_PERIOD == 0:\n",
    "            print('\\nEPOCH %d\\ttraining error=%10.12f'%(epoch_index,total_error[epoch_index]))\n",
    "            if validation_data is not None:\n",
    "                print('\\tvalidation_error=%10.12f'%(total_validation_error[epoch_index]))\n",
    "        \n",
    "        if total_error[epoch_index] < ERR_TERMINATION_COND:\n",
    "            training_ending_epoch = epoch_index\n",
    "            break\n",
    "\n",
    "    print('\\n\\n--\\nTRAINING ENDED AT EPOCH %d WITH training_error=%10.12f'%(training_ending_epoch, total_error[training_ending_epoch]))\n",
    "    print('\\nTRAINING ENDED AT EPOCH %d WITH validation_error=%10.12f'%(training_ending_epoch, total_validation_error[training_ending_epoch]))\n",
    "    \n",
    "    return w_h1, b_h1, w_h2, b_h2, w_out, b_out, total_error, total_validation_error, epochs, training_ending_epoch\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 0\ttraining error=0.880278460612\n",
      "\tvalidation_error=0.874214044785\n",
      "\n",
      "EPOCH 100\ttraining error=0.057552246594\n",
      "\tvalidation_error=0.069517414022\n",
      "\n",
      "EPOCH 200\ttraining error=0.036203742644\n",
      "\tvalidation_error=0.062006356848\n",
      "\n",
      "EPOCH 300\ttraining error=0.022736654561\n",
      "\tvalidation_error=0.031819651174\n",
      "\n",
      "EPOCH 400\ttraining error=0.015545649932\n",
      "\tvalidation_error=0.022870492138\n",
      "\n",
      "EPOCH 500\ttraining error=0.013092698825\n",
      "\tvalidation_error=0.018381199190\n",
      "\n",
      "EPOCH 600\ttraining error=0.009410036688\n",
      "\tvalidation_error=0.017668636368\n",
      "\n",
      "EPOCH 700\ttraining error=0.008813032687\n",
      "\tvalidation_error=0.015699748504\n",
      "\n",
      "EPOCH 800\ttraining error=0.008643960304\n",
      "\tvalidation_error=0.015793321088\n",
      "\n",
      "EPOCH 900\ttraining error=0.006569856341\n",
      "\tvalidation_error=0.014819690042\n",
      "\n",
      "EPOCH 1000\ttraining error=0.007422528568\n",
      "\tvalidation_error=0.015144376973\n",
      "\n",
      "EPOCH 1100\ttraining error=0.007258958067\n",
      "\tvalidation_error=0.015488149416\n",
      "\n",
      "EPOCH 1200\ttraining error=0.006203076653\n",
      "\tvalidation_error=0.017255230152\n",
      "\n",
      "EPOCH 1300\ttraining error=0.006293293722\n",
      "\tvalidation_error=0.015958177979\n",
      "\n",
      "EPOCH 1400\ttraining error=0.006327069342\n",
      "\tvalidation_error=0.015367303532\n",
      "\n",
      "EPOCH 1500\ttraining error=0.006039662905\n",
      "\tvalidation_error=0.016064772587\n",
      "\n",
      "EPOCH 1600\ttraining error=0.006000555787\n",
      "\tvalidation_error=0.015048629672\n",
      "\n",
      "EPOCH 1700\ttraining error=0.006023073152\n",
      "\tvalidation_error=0.015475107445\n",
      "\n",
      "EPOCH 1800\ttraining error=0.007141475256\n",
      "\tvalidation_error=0.017317328179\n",
      "\n",
      "EPOCH 1900\ttraining error=0.006178115616\n",
      "\tvalidation_error=0.015067785535\n",
      "\n",
      "EPOCH 2000\ttraining error=0.005884277623\n",
      "\tvalidation_error=0.015231412139\n",
      "\n",
      "EPOCH 2100\ttraining error=0.010373081159\n",
      "\tvalidation_error=0.015363950949\n",
      "\n",
      "EPOCH 2200\ttraining error=0.006069095791\n",
      "\tvalidation_error=0.014753886795\n"
     ]
    }
   ],
   "source": [
    "w_h1, b_h1, w_h2, b_h2, w_out, b_out, total_training_error, total_validation_error, epochs, training_ending_epoch = train_fourlayer_neural_net(train_data, train_labels,\n",
    "                                                                                                                       NUM_INPUT, NUM_HIDDEN1_NEURONS,\n",
    "                                                                                                                       NUM_HIDDEN2_NEURONS, NUM_OUTPUT,\n",
    "                                                                                                                       validation_data, validation_labels)\n",
    "from playsound import playsound\n",
    "playsound('Victory.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig= plt.figure(figsize=(6,3))\n",
    "axes= fig.add_axes([0, training_ending_epoch, 0, max(np.max(total_training_error), np.max(total_validation_error))])\n",
    "axes.plot(epochs, total_training_error, epochs, total_validation_error)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#plt.plot(epochs, total_training_error, epochs, total_validation_error)\n",
    "#plt.axis([0, training_ending_epoch, 0, max(np.max(total_training_error), np.max(total_validation_error))])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
