{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS280 Programming Assignment 2\n",
    "__Implementing the Backpropagation Algorithm__<br>\n",
    "<br>\n",
    "Compiler: Python 3.6.5<br>\n",
    "OS: Windows 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.genfromtxt('training_set.csv', delimiter=',')\n",
    "train_labels = np.genfromtxt('training_labels.csv', delimiter=',')\n",
    "\n",
    "validation_data = np.genfromtxt('validation_set.csv', delimiter=',')\n",
    "validation_labels = np.genfromtxt('validation_labels.csv', delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_to_onehotvector(labels):\n",
    "    unique_labels, label_counts = np.unique(labels, return_counts=True)\n",
    "    onehotvector = np.zeros((len(labels), len(unique_labels)))\n",
    "    for index, label in enumerate(labels):\n",
    "        onehotvector[int(index), int(label)-1] = int(1)\n",
    "    return onehotvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = labels_to_onehotvector(train_labels)\n",
    "validation_labels = labels_to_onehotvector(validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7674, 354), (7674, 8), (1910, 354), (1910, 8))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, train_labels.shape, validation_data.shape, validation_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data = np.array([[0, 0, 0],\n",
    "#                       [0, 0, 1],\n",
    "#                       [0, 1, 0],\n",
    "#                       [0, 1, 1],\n",
    "#                       [1, 0, 0],\n",
    "#                       [1, 0, 1],\n",
    "#                       [1, 1, 0],\n",
    "#                       [1, 1, 1]])\n",
    "#train_labels = np.array([[0, 0, 0],\n",
    "#                       [1, 1, 0],\n",
    "#                       [1, 0, 1],\n",
    "#                       [0, 1, 1],\n",
    "#                       [0, 1, 1],\n",
    "#                       [1, 0, 0],\n",
    "#                       [1, 1, 0],\n",
    "#                       [0, 0, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Neural network\n",
    "Define architecture of Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_INPUT = train_data.shape[1]\n",
    "NUM_HIDDEN1_NEURONS = 7\n",
    "NUM_HIDDEN2_NEURONS = 5\n",
    "NUM_OUTPUT = train_labels.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Learning Rate, LR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare the matrices for the weights and biases, and then initialize them with random numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_neurons(num_input, num_hidden1_neurons, num_hidden2_neurons, num_output):\n",
    "    \n",
    "    INIT_RANGE = 0.1\n",
    "\n",
    "    x_in = np.zeros((num_input, 1))\n",
    "\n",
    "    w_h1 = np.random.uniform(low=-INIT_RANGE, high=INIT_RANGE, size=(num_hidden1_neurons, num_input))\n",
    "    b_h1 = np.random.uniform(low=-INIT_RANGE, high=INIT_RANGE, size=(num_hidden1_neurons, 1))\n",
    "\n",
    "    w_h2 = np.random.uniform(low=-INIT_RANGE, high=INIT_RANGE, size=(num_hidden2_neurons, num_hidden1_neurons))\n",
    "    b_h2 = np.random.uniform(low=-INIT_RANGE, high=INIT_RANGE, size=(num_hidden2_neurons, 1))\n",
    "\n",
    "    w_out = np.random.uniform(low=-INIT_RANGE, high=INIT_RANGE, size=(num_output, num_hidden2_neurons))\n",
    "    b_out = np.random.uniform(low=-INIT_RANGE, high=INIT_RANGE, size=(num_output, 1))\n",
    "\n",
    "    d_out = np.zeros((num_output, 1))\n",
    "    \n",
    "    return x_in, w_h1, b_h1, w_h2, b_h2, w_out, b_out, d_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Phase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_data, w_h1, b_h1, w_h2, b_h2, w_out, b_out):\n",
    "    ##### FORWARD PASS #####\n",
    "    ## HIDDEN LAYER 1\n",
    "    v_h1 = np.dot(w_h1,input_data) + b_h1\n",
    "    y_h1 = 1/(1 + np.exp(-v_h1))\n",
    "    ## HIDDEN LAYER 2\n",
    "    v_h2 = np.dot(w_h2, y_h1) + b_h2\n",
    "    y_h2 = 1/(1 + np.exp(-v_h2))            \n",
    "    ## OUTPUT LAYER\n",
    "    v_out = np.dot(w_out, y_h2) + b_out\n",
    "    out = 1/(1 + np.exp(-v_out))\n",
    "    \n",
    "    return out, y_h1, y_h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fourlayer_neural_net(train_data, train_labels,num_input, num_hidden1_neurons,\n",
    "                               num_hidden2_neurons, num_output, validation_data=None, validation_labels=None):\n",
    "    \n",
    "    MAX_EPOCH = 30000\n",
    "    ERR_REPORT_PERIOD = 100 # Print error report every __ epochs\n",
    "    ERR_TERMINATION_COND = 0.0010000000000\n",
    "\n",
    "    x_in, w_h1, b_h1, w_h2, b_h2, w_out, b_out, d_out = init_neurons(num_input,\n",
    "                                                                     num_hidden1_neurons,\n",
    "                                                                     num_hidden2_neurons,\n",
    "                                                                     num_output)\n",
    "    # Initialize\n",
    "    total_error = np.zeros((MAX_EPOCH, 1))\n",
    "    total_validation_error = np.zeros((MAX_EPOCH, 1))\n",
    "    training_ending_epoch = MAX_EPOCH\n",
    "    epochs = range(0, MAX_EPOCH)\n",
    "    \n",
    "    for epoch_index in epochs:\n",
    "        train_indices = np.random.permutation(train_data.shape[0])\n",
    "        for train_index in train_indices:\n",
    "            # READ DATA\n",
    "            x_in = train_data[train_index].reshape(-1, 1)\n",
    "            d_out = train_labels[train_index].reshape(-1, 1)\n",
    "\n",
    "            ##### FORWARD PASS #####\n",
    "            out, y_h1, y_h2 = predict(x_in, w_h1, b_h1, w_h2, b_h2, w_out, b_out)\n",
    "            \n",
    "            ##### BACK PROPAGATION #####\n",
    "            error = d_out - out\n",
    "            #print('\\terror: ', error, '\\n')\n",
    "            delta_out = error*out*(1-out)\n",
    "            #print('delta-out.shape=',delta_out.shape)\n",
    "            #print('(1-y_h2).shape=',(1-y_h2).shape, ' y_h2*(1-y_h2).shape=', (y_h2*(1-y_h2)).shape, ' np.dot(w_out,delta_out).shape=', (np.dot(np.transpose(w_out),delta_out)).shape)\n",
    "            delta_h2 = (y_h2*(1-y_h2))*(np.dot(np.transpose(w_out),delta_out))\n",
    "            delta_h1 = (y_h1*(1-y_h1))*(np.dot(np.transpose(w_h2), delta_h2))\n",
    "\n",
    "            ## Update the weights and biases\n",
    "            w_out = w_out + LR*delta_out*np.transpose(y_h2)\n",
    "            b_out = b_out + LR*delta_out\n",
    "            \n",
    "            w_h2 = w_h2 + LR*delta_h2*np.transpose(y_h1)\n",
    "            b_h2 = b_h2 + LR*delta_h2\n",
    "            \n",
    "            w_h1 = w_h1 + LR*delta_h1*np.transpose(x_in)\n",
    "            b_h1 = b_h1 + LR*delta_h1\n",
    "            \n",
    "            total_error[epoch_index] = total_error[epoch_index] + (np.sum(error*error))/len(error)\n",
    "        \n",
    "        total_error[epoch_index] *= (1/train_data.shape[0])\n",
    "        \n",
    "        if validation_data is not None:\n",
    "            for validation_index, data in enumerate(validation_data):\n",
    "                validation_x_in = validation_data[validation_index].reshape(-1, 1)\n",
    "                validation_d_out = validation_labels[validation_index].reshape(-1, 1)\n",
    "                validation_out, dummy1, dummy2 = predict(validation_x_in,\n",
    "                                         w_h1, b_h1, w_h2, b_h2, w_out, b_out)\n",
    "                validation_error = validation_d_out - validation_out\n",
    "                total_validation_error[epoch_index] = total_validation_error[epoch_index] + (np.sum(validation_error*validation_error))/len(validation_error)\n",
    "            total_validation_error[epoch_index] *= (1/validation_data.shape[0])\n",
    "        \n",
    "        if epoch_index % ERR_REPORT_PERIOD == 0:\n",
    "            print('\\nEPOCH %d\\ttraining error=%10.12f'%(epoch_index,total_error[epoch_index]))\n",
    "            if validation_data is not None:\n",
    "                print('\\tvalidation_error=%10.12f'%(total_validation_error[epoch_index]))\n",
    "        \n",
    "        if total_error[epoch_index] < ERR_TERMINATION_COND:\n",
    "            training_ending_epoch = epoch_index\n",
    "            break\n",
    "\n",
    "    print('\\n\\n--\\nTRAINING ENDED AT EPOCH %d WITH training_error=%10.12f'%(training_ending_epoch, total_error[training_ending_epoch]))\n",
    "    print('\\nTRAINING ENDED AT EPOCH %d WITH validation_error=%10.12f'%(training_ending_epoch, total_validation_error[training_ending_epoch]))\n",
    "    \n",
    "    return w_h1, b_h1, w_h2, b_h2, w_out, b_out, total_error, total_validation_error, epochs, training_ending_epoch\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 0\ttraining error=0.110076878629\n",
      "\tvalidation_error=0.109171483373\n",
      "\n",
      "EPOCH 100\ttraining error=0.006488580207\n",
      "\tvalidation_error=0.006252806058\n",
      "\n",
      "EPOCH 200\ttraining error=0.003311615703\n",
      "\tvalidation_error=0.004366909987\n",
      "\n",
      "EPOCH 300\ttraining error=0.002781198973\n",
      "\tvalidation_error=0.002905500723\n",
      "\n",
      "EPOCH 400\ttraining error=0.002182091695\n",
      "\tvalidation_error=0.003025048562\n",
      "\n",
      "EPOCH 500\ttraining error=0.001918314478\n",
      "\tvalidation_error=0.004366386864\n",
      "\n",
      "EPOCH 600\ttraining error=0.001221000979\n",
      "\tvalidation_error=0.002800448612\n",
      "\n",
      "\n",
      "--\n",
      "TRAINING ENDED AT EPOCH 678 WITH training_error=0.000968234639\n",
      "\n",
      "TRAINING ENDED AT EPOCH 678 WITH validation_error=0.002660561896\n"
     ]
    }
   ],
   "source": [
    "w_h1, b_h1, w_h2, b_h2, w_out, b_out, total_training_error, total_validation_error, epochs, training_ending_epoch = train_fourlayer_neural_net(train_data, train_labels,\n",
    "                                                                                                                       NUM_INPUT, NUM_HIDDEN1_NEURONS,\n",
    "                                                                                                                       NUM_HIDDEN2_NEURONS, NUM_OUTPUT,\n",
    "                                                                                                                       validation_data, validation_labels)\n",
    "from playsound import playsound\n",
    "playsound('Victory.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(epochs, total_training_error, epochs, total_validation_error)\n",
    "plt.axis([0, training_ending_epoch, 0, max(np.max(total_training_error), np.max(total_validation_error))])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
