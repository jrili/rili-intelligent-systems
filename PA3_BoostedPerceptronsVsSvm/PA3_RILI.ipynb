{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS280 Programming Assignment 3\n",
    "__Comparison of Boosted Perceptrons and SVM__<br>\n",
    "<br>\n",
    "Compiler: Python 3.6.5<br>\n",
    "OS: Windows 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Perceptron Classifier Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Generate data\n",
    "Generate data consisting of 100 two-dimensional vectors taken from a normal distribution with $\\mu_{1} = [0,0]^{T}$, $\\sigma_{1} = I$ and label them as class \"$-1$\"<br>\n",
    "<br>\n",
    "Form a class \"$-1$\" training subset by setting aside 50 points and let the remaining 50 points serve as part of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_random_data(mean, standard_dev, data_size, train_test_split, label):\n",
    "    data = np.random.normal(mean, standard_dev, size=data_size)\n",
    "    \n",
    "    train_data = data[ :int(train_test_split*data.shape[0])]\n",
    "    train_labels = label * np.ones(train_data.shape[0])\n",
    "    \n",
    "    test_data = data[int(train_test_split*data.shape[0]): ]\n",
    "    test_labels = label * np.ones(test_data.shape[0])\n",
    "    \n",
    "    return train_data, train_labels, test_data, test_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_DATA_POINTS = 100\n",
    "NUM_DATA_DIM = 2\n",
    "\n",
    "mean = 0\n",
    "std = 1\n",
    "\n",
    "classneg1_train_data, classneg1_train_labels, classneg1_test_data, classneg1_test_labels = generate_random_data(mean, std, [NUM_DATA_POINTS, NUM_DATA_DIM], 0.5, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same for class \"+1\" for another normal distribution with $\\mu_{2} = [0,0]^{T}$, $\\sigma_{2} = I$. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classpos1_train_data, classpos1_train_labels, classpos1_test_data, classpos1_test_labels = generate_random_data(mean, std, [NUM_DATA_POINTS, NUM_DATA_DIM], 0.5, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the subsets to form the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(data, labels):\n",
    "    indices = np.arange(data.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    data = data[indices, :]\n",
    "    labels = labels[indices]\n",
    "    return data, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, train_labels = shuffle_data(np.concatenate((classneg1_train_data, classpos1_train_data)), np.concatenate((classneg1_train_labels, classpos1_train_labels)))\n",
    "test_set, test_labels = shuffle_data(np.concatenate((classneg1_test_data, classpos1_test_data)), np.concatenate((classneg1_test_labels, classpos1_test_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Write code _classify(...)_\n",
    "Write code named _classify(...)_ that implements the Pocket Algorithm for perceptron learning.<br>\n",
    "Set _maxitercnt_ to 10000 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def classify(train_set, train_labels, maxitercnt=10000):\n",
    "    # Number of features, d\n",
    "    d = train_set.shape[1]\n",
    "\n",
    "    # Number of training samples\n",
    "    N = train_set.shape[0]\n",
    "\n",
    "    # Number of consecutive iterations for which v correctly classified the examples\n",
    "    n_v = 0\n",
    "\n",
    "    # Number of consecutive iterations for which w correctly classified the examples\n",
    "    n_w = 0\n",
    "\n",
    "    w = np.random.uniform(low=-0.1, high=0.1, size=(d+1, 1))\n",
    "    v = w\n",
    "    print(\"\\t'-'-'-'-'-'-'-'-'-'-'-'-'-'-\")\n",
    "    print('\\tPocket Algorithm training started:\\n\\t\\t', end='')\n",
    "    for itercnt in range(maxitercnt):\n",
    "        if itercnt % int(maxitercnt/20) == 0:\n",
    "            print('.', end='')\n",
    "        random_index = random.sample(range(N), 1)\n",
    "        x_j = np.insert(train_set[random_index], 0, 1)\n",
    "        y_j = train_labels[random_index]\n",
    "\n",
    "        y_j_hat = 1 if (np.inner(v.transpose(), x_j) >= 0) else -1\n",
    "\n",
    "        if y_j*y_j_hat > 0:\n",
    "            n_v += 1\n",
    "            #print('\\t\\tweight vector v correctly predicted label!')\n",
    "        else:\n",
    "            #print('\\t\\tweight vector v incorrectly predicted label! Putting in pocket...')\n",
    "            if n_v > n_w:\n",
    "                #print('\\n\\t\\t@Pocket Algorithm Iteration # %d of %d: FOUND NEW BEST W with n_w=%d!\\n\\t\\t' % (itercnt+1, maxitercnt, n_w), end='')\n",
    "                w = v\n",
    "                n_w = n_v\n",
    "            v = v + (y_j*x_j).reshape(-1, 1)\n",
    "            n_v = 0\n",
    "        \n",
    "    print('\\n\\tPocket Algorithm training ended with n_w=%d, w=:' % (n_w), w.transpose() )\n",
    "    print(\"\\t'-'-'-'-'-'-'-'-'-'-'-'-'-'-\")\n",
    "        \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t'-'-'-'-'-'-'-'-'-'-'-'-'-'-\n",
      "\tPocket Algorithm training started:\n",
      "\t\t....................\n",
      "\tPocket Algorithm training ended with n_w=19, w=: [[ 0.09442872 -0.5047732   2.68514097]]\n",
      "\t'-'-'-'-'-'-'-'-'-'-'-'-'-'-\n"
     ]
    }
   ],
   "source": [
    "maxitercnt = 10000\n",
    "pocket_w = classify(train_set, train_labels, maxitercnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Write code _predict()_\n",
    "Write code named _predict(...)_ to test the classifier and  measure the sum of square errors for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_data, w, true_labels=None):\n",
    "    x_j = np.insert(input_data, 0, 1, axis=1)\n",
    "    error = 0\n",
    "    \n",
    "    predicted_labels = np.zeros((input_data.shape[0], 1))\n",
    "    for index in range(x_j.shape[0]):\n",
    "        prod = np.inner(w.transpose(), x_j[index, :].reshape(1,-1))\n",
    "        predicted_labels[index] = 1 if (prod >= 0) else -1\n",
    "        \n",
    "    if true_labels is not None:    \n",
    "        error = (1/len(true_labels))*np.sum(np.square(true_labels - predicted_labels))\n",
    "    \n",
    "    return predicted_labels, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels, error = predict(test_set, pocket_w, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Adaboost Construction and Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Write code _adabtrain()_\n",
    "Write code called _adabtrain()_ that implements the Adaboost algorithm with the Pocket Algorithm as the basic learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def adabtrain(data, labels, K=10):\n",
    "    N = data.shape[0]\n",
    "    w = np.full((data.shape[0],1), 1/N)\n",
    "    alpha = np.zeros(K)\n",
    "    h = np.zeros((K, data.shape[1]+1))\n",
    "    print('w.shape = ', len(w), ' h.shape = ', h.shape, ' alpha.shape = ', alpha.shape)\n",
    "    \n",
    "    for iter in range(K):\n",
    "        print(\"=======================================================\")\n",
    "        print(\"ADABOOST ITERATION # %d of %d\" % (iter+1, K))\n",
    "        print(\"=======================================================\")\n",
    "\n",
    "        eps = 1\n",
    "        y_t = np.zeros(labels.shape)\n",
    "        L_weights = np.zeros((data.shape[1]+1))\n",
    "        h_t_of_x = np.zeros(labels.shape)\n",
    "        while(eps >= 0.5):\n",
    "            s_t_indices = np.random.choice(np.arange(labels.size), size=labels.shape, replace=True, p=w.transpose().tolist()[0])\n",
    "            y_t = labels[s_t_indices]\n",
    "            L_weights = classify(data[s_t_indices], y_t)\n",
    "\n",
    "            h_t_of_x, _ = predict(data[s_t_indices], L_weights)\n",
    "\n",
    "            delta = np.not_equal(labels.reshape(-1, 1), h_t_of_x)\n",
    "            eps = np.sum(w*delta)\n",
    "\n",
    "            print('\\n\\tADABOOST training_error = ', eps)\n",
    "            if eps >= 0.5:\n",
    "                print('\\n\\t!! ADABOOST training_error is >= 0.5! Re-sampling.... !!\\n')\n",
    "                iter -= 1\n",
    "    \n",
    "        alpha_t = (0.5)*np.log((1-eps)/(eps))\n",
    "        \n",
    "        def update_w(w_t, alpha_t, y_s_t, h_t):\n",
    "            new_w = w_t*(np.exp(-alpha_t*y_s_t*h_t.transpose())).transpose()\n",
    "            z_t = np.sum(new_w)\n",
    "            \n",
    "            new_w = new_w/z_t\n",
    "            return new_w\n",
    "        \n",
    "        w = update_w(w, alpha_t, y_t, h_t_of_x)\n",
    "        h[iter] = list(L_weights)\n",
    "        alpha[iter] = alpha_t\n",
    "        \n",
    "    return \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Form the training set\n",
    "Form the training set by sampling 400 points from the banana dataset provided. Use the remaining 4900 points as your test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = np.genfromtxt('banana_data.csv', delimiter=',')\n",
    "all_data = np.genfromtxt('banana_data.csv', delimiter=',')[ : , 1:]\n",
    "all_labels = np.genfromtxt('banana_data.csv', delimiter=',')[ : , 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((400, 2), (400,), (4900, 2), (4900,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_TRAIN_POINTS = 400\n",
    "NUM_TEST_POINTS = 4900\n",
    "\n",
    "train_indices = np.random.choice(all_data.shape[0], NUM_TRAIN_POINTS, replace=False)\n",
    "test_indices = np.array([x for x in np.arange(all_data.shape[0]) if x not in train_indices])\n",
    "\n",
    "train_data = all_data[train_indices]\n",
    "train_labels = all_labels[train_indices]\n",
    "\n",
    "test_data = all_data[test_indices]\n",
    "test_labels = all_labels[test_indices]\n",
    "\n",
    "train_data.shape, train_labels.shape, test_data.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Write code named _adabpredict()_\n",
    "Write code named adabpredict() that classifies unknown/unseen data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Train the boosted perceptron algorithm\n",
    "Using _adabtrain()_ and _adabpredict()_, train the boosted perceptron algorithm and measure the training and test accuracies for the ensemble classifier having *K* learners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w.shape =  400  h.shape =  (10, 3)  alpha.shape =  (10,)\n",
      "=======================================================\n",
      "ADABOOST ITERATION # 1 of 10\n",
      "=======================================================\n",
      "\t'-'-'-'-'-'-'-'-'-'-'-'-'-'-\n",
      "\tPocket Algorithm training started:\n",
      "\t\t....................\n",
      "\tPocket Algorithm training ended with n_w=13, w=: [[ 0.00741679 -0.2337937  -2.30477835]]\n",
      "\t'-'-'-'-'-'-'-'-'-'-'-'-'-'-\n",
      "\n",
      "\tADABOOST training_error =  0.47250000000000003\n",
      "=======================================================\n",
      "ADABOOST ITERATION # 2 of 10\n",
      "=======================================================\n",
      "\t'-'-'-'-'-'-'-'-'-'-'-'-'-'-\n",
      "\tPocket Algorithm training started:\n",
      "\t\t....................\n",
      "\tPocket Algorithm training ended with n_w=13, w=: [[ 0.03413976 -0.0720089  -2.25249663]]\n",
      "\t'-'-'-'-'-'-'-'-'-'-'-'-'-'-\n",
      "\n",
      "\tADABOOST training_error =  0.5369233489970189\n",
      "\t\n",
      "!! ADABOOST training_error is >= 0.5! Re-sampling.... !!\n",
      "\n",
      "\t'-'-'-'-'-'-'-'-'-'-'-'-'-'-\n",
      "\tPocket Algorithm training started:\n",
      "\t\t....................\n",
      "\tPocket Algorithm training ended with n_w=13, w=: [[ 0.91729303 -0.89865653 -1.70120578]]\n",
      "\t'-'-'-'-'-'-'-'-'-'-'-'-'-'-\n",
      "\n",
      "\tADABOOST training_error =  0.5044969935829418\n",
      "\t\n",
      "!! ADABOOST training_error is >= 0.5! Re-sampling.... !!\n",
      "\n",
      "\t'-'-'-'-'-'-'-'-'-'-'-'-'-'-\n",
      "\tPocket Algorithm training started:\n",
      "\t\t....................\n",
      "\tPocket Algorithm training ended with n_w=12, w=: [[ 0.98424355 -0.14115211 -2.35961867]]\n",
      "\t'-'-'-'-'-'-'-'-'-'-'-'-'-'-\n",
      "\n",
      "\tADABOOST training_error =  0.5063286342276794\n",
      "\t\n",
      "!! ADABOOST training_error is >= 0.5! Re-sampling.... !!\n",
      "\n",
      "\t'-'-'-'-'-'-'-'-'-'-'-'-'-'-\n",
      "\tPocket Algorithm training started:\n",
      "\t\t....................\n",
      "\tPocket Algorithm training ended with n_w=14, w=: [[ 0.95710107 -1.55321091 -1.94403008]]\n",
      "\t'-'-'-'-'-'-'-'-'-'-'-'-'-'-\n",
      "\n",
      "\tADABOOST training_error =  0.48567530695770805\n",
      "=======================================================\n",
      "ADABOOST ITERATION # 3 of 10\n",
      "=======================================================\n",
      "\t'-'-'-'-'-'-'-'-'-'-'-'-'-'-\n",
      "\tPocket Algorithm training started:\n",
      "\t\t....................\n",
      "\tPocket Algorithm training ended with n_w=14, w=: [[ 0.91626031 -0.60972014 -1.37223618]]\n",
      "\t'-'-'-'-'-'-'-'-'-'-'-'-'-'-\n",
      "\n",
      "\tADABOOST training_error =  0.4500099754521658\n",
      "=======================================================\n",
      "ADABOOST ITERATION # 4 of 10\n",
      "=======================================================\n",
      "\t'-'-'-'-'-'-'-'-'-'-'-'-'-'-\n",
      "\tPocket Algorithm training started:\n",
      "\t\t....................\n",
      "\tPocket Algorithm training ended with n_w=14, w=: [[ 0.9666087  -1.45664429 -2.44008846]]\n",
      "\t'-'-'-'-'-'-'-'-'-'-'-'-'-'-\n",
      "\n",
      "\tADABOOST training_error =  0.5059894632773195\n",
      "\t\n",
      "!! ADABOOST training_error is >= 0.5! Re-sampling.... !!\n",
      "\n",
      "\t'-'-'-'-'-'-'-'-'-'-'-'-'-'-\n",
      "\tPocket Algorithm training started:\n",
      "\t\t....................\n",
      "\tPocket Algorithm training ended with n_w=21, w=: [[ 0.90412561 -1.21094255 -2.74263724]]\n",
      "\t'-'-'-'-'-'-'-'-'-'-'-'-'-'-\n",
      "\n",
      "\tADABOOST training_error =  0.5233516189383358\n",
      "\t\n",
      "!! ADABOOST training_error is >= 0.5! Re-sampling.... !!\n",
      "\n",
      "\t'-'-'-'-'-'-'-'-'-'-'-'-'-'-\n",
      "\tPocket Algorithm training started:\n",
      "\t\t....................\n",
      "\tPocket Algorithm training ended with n_w=14, w=: [[ 1.01239421 -0.5153885  -2.57616017]]\n",
      "\t'-'-'-'-'-'-'-'-'-'-'-'-'-'-\n",
      "\n",
      "\tADABOOST training_error =  0.4888921370022486\n",
      "=======================================================\n",
      "ADABOOST ITERATION # 5 of 10\n",
      "=======================================================\n",
      "\t'-'-'-'-'-'-'-'-'-'-'-'-'-'-\n",
      "\tPocket Algorithm training started:\n",
      "\t\t....................\n",
      "\tPocket Algorithm training ended with n_w=14, w=: [[ 0.05178767 -0.28110365  0.1286336 ]]\n",
      "\t'-'-'-'-'-'-'-'-'-'-'-'-'-'-\n",
      "\n",
      "\tADABOOST training_error =  0.4951390358932344\n",
      "=======================================================\n",
      "ADABOOST ITERATION # 6 of 10\n",
      "=======================================================\n",
      "\t'-'-'-'-'-'-'-'-'-'-'-'-'-'-\n",
      "\tPocket Algorithm training started:\n",
      "\t\t....................\n",
      "\tPocket Algorithm training ended with n_w=14, w=: [[ 1.06845902 -1.4805402  -0.53981511]]\n",
      "\t'-'-'-'-'-'-'-'-'-'-'-'-'-'-\n",
      "\n",
      "\tADABOOST training_error =  0.47716286633381266\n",
      "=======================================================\n",
      "ADABOOST ITERATION # 7 of 10\n",
      "=======================================================\n",
      "\t'-'-'-'-'-'-'-'-'-'-'-'-'-'-\n",
      "\tPocket Algorithm training started:\n",
      "\t\t....................\n",
      "\tPocket Algorithm training ended with n_w=13, w=: [[-0.98794888 -1.0185507   0.98927597]]\n",
      "\t'-'-'-'-'-'-'-'-'-'-'-'-'-'-\n",
      "\n",
      "\tADABOOST training_error =  0.4719872858014407\n",
      "=======================================================\n",
      "ADABOOST ITERATION # 8 of 10\n",
      "=======================================================\n",
      "\t'-'-'-'-'-'-'-'-'-'-'-'-'-'-\n",
      "\tPocket Algorithm training started:\n",
      "\t\t....................\n",
      "\tPocket Algorithm training ended with n_w=13, w=: [[ 2.06617081  0.74144394 -1.64134991]]\n",
      "\t'-'-'-'-'-'-'-'-'-'-'-'-'-'-\n",
      "\n",
      "\tADABOOST training_error =  0.5426064572886748\n",
      "\t\n",
      "!! ADABOOST training_error is >= 0.5! Re-sampling.... !!\n",
      "\n",
      "\t'-'-'-'-'-'-'-'-'-'-'-'-'-'-\n",
      "\tPocket Algorithm training started:\n",
      "\t\t....................\n",
      "\tPocket Algorithm training ended with n_w=16, w=: [[0.039983   1.44947904 0.16210825]]\n",
      "\t'-'-'-'-'-'-'-'-'-'-'-'-'-'-\n",
      "\n",
      "\tADABOOST training_error =  0.506118319594806\n",
      "\t\n",
      "!! ADABOOST training_error is >= 0.5! Re-sampling.... !!\n",
      "\n",
      "\t'-'-'-'-'-'-'-'-'-'-'-'-'-'-\n",
      "\tPocket Algorithm training started:\n",
      "\t\t....................\n",
      "\tPocket Algorithm training ended with n_w=13, w=: [[-0.9957134  -0.06217307  0.7896321 ]]\n",
      "\t'-'-'-'-'-'-'-'-'-'-'-'-'-'-\n",
      "\n",
      "\tADABOOST training_error =  0.48947884340286785\n",
      "=======================================================\n",
      "ADABOOST ITERATION # 9 of 10\n",
      "=======================================================\n",
      "\t'-'-'-'-'-'-'-'-'-'-'-'-'-'-\n",
      "\tPocket Algorithm training started:\n",
      "\t\t....................\n",
      "\tPocket Algorithm training ended with n_w=15, w=: [[ 0.06701165 -0.95928191 -1.31336321]]\n",
      "\t'-'-'-'-'-'-'-'-'-'-'-'-'-'-\n",
      "\n",
      "\tADABOOST training_error =  0.49340335571523775\n",
      "=======================================================\n",
      "ADABOOST ITERATION # 10 of 10\n",
      "=======================================================\n",
      "\t'-'-'-'-'-'-'-'-'-'-'-'-'-'-\n",
      "\tPocket Algorithm training started:\n",
      "\t\t....................\n",
      "\tPocket Algorithm training ended with n_w=14, w=: [[0.09697018 2.01973097 0.59282493]]\n",
      "\t'-'-'-'-'-'-'-'-'-'-'-'-'-'-\n",
      "\n",
      "\tADABOOST training_error =  0.5073049186370917\n",
      "\t\n",
      "!! ADABOOST training_error is >= 0.5! Re-sampling.... !!\n",
      "\n",
      "\t'-'-'-'-'-'-'-'-'-'-'-'-'-'-\n",
      "\tPocket Algorithm training started:\n",
      "\t\t....................\n",
      "\tPocket Algorithm training ended with n_w=20, w=: [[ 0.0661825  -0.61516278 -1.39847357]]\n",
      "\t'-'-'-'-'-'-'-'-'-'-'-'-'-'-\n",
      "\n",
      "\tADABOOST training_error =  0.5060390919650988\n",
      "\t\n",
      "!! ADABOOST training_error is >= 0.5! Re-sampling.... !!\n",
      "\n",
      "\t'-'-'-'-'-'-'-'-'-'-'-'-'-'-\n",
      "\tPocket Algorithm training started:\n",
      "\t\t....................\n",
      "\tPocket Algorithm training ended with n_w=12, w=: [[-0.91510035  1.41500759 -0.92737184]]\n",
      "\t'-'-'-'-'-'-'-'-'-'-'-'-'-'-\n",
      "\n",
      "\tADABOOST training_error =  0.5004511562875277\n",
      "\t\n",
      "!! ADABOOST training_error is >= 0.5! Re-sampling.... !!\n",
      "\n",
      "\t'-'-'-'-'-'-'-'-'-'-'-'-'-'-\n",
      "\tPocket Algorithm training started:\n",
      "\t\t....................\n",
      "\tPocket Algorithm training ended with n_w=13, w=: [[-0.94079116  1.31067069 -0.07282552]]\n",
      "\t'-'-'-'-'-'-'-'-'-'-'-'-'-'-\n",
      "\n",
      "\tADABOOST training_error =  0.44495233783721566\n"
     ]
    }
   ],
   "source": [
    "adabtrain(train_data,train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. Write code that automatically plots accuracies\n",
    "Write code that automatially plots the training and test accuracies against the number of learners *K* used for training. Use *K*= 10, 20, 30, ...., 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6. Train and test your Boosted Perceptron on the splice dataset\n",
    "Train and test you Boosted perceptron on the splice dataset and plot the accuracy vs _K_ curves for both training and test. Use 1000 points for training, 2175 points for test, and K = 10, 20, 30, ..., 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Classifier\n",
    "You have been provided LibSVM. Familiarize yourself with the codes. Compile it and test the codes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Form a training dataset of 400 points and test set of 4900 points from banana dataset.<br>\n",
    "<br>\n",
    "Run the Support Vector Machine Classifier on these sets. Find the kernel and kernal parameters to obtain the best performance.<br>\n",
    "<br>\n",
    "Repeat for the splice dataset with 1000 training points and 2175 test points.<br>\n",
    "<br>\n",
    "Compare the performance of SVM with Boosted Perceptrons in terms of test accuracy, training and test speeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
